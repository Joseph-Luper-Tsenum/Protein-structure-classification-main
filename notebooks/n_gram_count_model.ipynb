{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Hands-on Challenge - Data preparation and exploration\n",
    "\n",
    "This notebook contains the N-gram count model for the ML Hands-on Challenge. The N-gram count model is a simple model that counts the number of occurrences of each N-gram in the training data and uses these counts to predict the protein structure CATH class. The N-gram count model is a simple baseline model that can be used to compare the performance of more complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import Bio.PDB.PDBParser\n",
    "import py3Dmol\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Used element '.' for Atom\")\n",
    "\n",
    "# Get parent directory and add src/ to pythonpath\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from src.config import CONSTANTS\n",
    "from src.pdb import *\n",
    "\n",
    "DATA_HOME = os.path.join(parent_dir, CONSTANTS.DATA_HOME)\n",
    "SEED = CONSTANTS.SEED\n",
    "architecture_names = CONSTANTS.ARCHITECTURE_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading processed data from the [`data_prep_exploration.ipynb`](./data_prep_exploration.ipynb) notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cath_id</th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>class</th>\n",
       "      <th>architecture</th>\n",
       "      <th>topology</th>\n",
       "      <th>superfamily</th>\n",
       "      <th>resolution_in_angstroms</th>\n",
       "      <th>sequence</th>\n",
       "      <th>piece_edges</th>\n",
       "      <th>num_residues</th>\n",
       "      <th>domain_edges</th>\n",
       "      <th>total_num_residues</th>\n",
       "      <th>num_gaps</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2w3sB01</td>\n",
       "      <td>2w3s</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>1170</td>\n",
       "      <td>50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>SVGKPLPHDSARAHVTGQARYLDDLPCPANTLHLAFGLSTEASAAI...</td>\n",
       "      <td>[(2, 124)]</td>\n",
       "      <td>123</td>\n",
       "      <td>[2, 124]</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3be3A00</td>\n",
       "      <td>3be3</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>320</td>\n",
       "      <td>2.04</td>\n",
       "      <td>QDFRPGVYRHYKGDHYLALGLARADETDEVVVVYTRLYARAGLPST...</td>\n",
       "      <td>[(6, 49), (51, 81)]</td>\n",
       "      <td>75</td>\n",
       "      <td>[6, 81]</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3zq4C03</td>\n",
       "      <td>3zq4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>580</td>\n",
       "      <td>3.00</td>\n",
       "      <td>DIGNIVLRDRRILSEEGLVIVVVSIDMDDFKISAGPDLISRGFVIN...</td>\n",
       "      <td>[(449, 492), (501, 555)]</td>\n",
       "      <td>99</td>\n",
       "      <td>[449, 555]</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1peqA03</td>\n",
       "      <td>1peq</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1650</td>\n",
       "      <td>20</td>\n",
       "      <td>2.80</td>\n",
       "      <td>DITFRLAKENAQMALFSPYDIQRRYGKPFGDIAISERYDELIADPH...</td>\n",
       "      <td>[(294, 346)]</td>\n",
       "      <td>53</td>\n",
       "      <td>[294, 346]</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1bdoA00</td>\n",
       "      <td>1bdo</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>1.80</td>\n",
       "      <td>EISGHIVRSPMVGTFYRTPSPDAKAFIEVGQKVNVGDTLCIVEAMK...</td>\n",
       "      <td>[(77, 156)]</td>\n",
       "      <td>80</td>\n",
       "      <td>[77, 156]</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6263</th>\n",
       "      <td>2yyiA02</td>\n",
       "      <td>2yyi</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>110</td>\n",
       "      <td>10</td>\n",
       "      <td>1.66</td>\n",
       "      <td>ATTHALTNPQVNRARPPSGQPDPYIPVGVVKQTEKGIVVRGARMTA...</td>\n",
       "      <td>[(139, 196), (199, 266)]</td>\n",
       "      <td>126</td>\n",
       "      <td>[139, 266]</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>4mo0A00</td>\n",
       "      <td>4mo0</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>780</td>\n",
       "      <td>10</td>\n",
       "      <td>2.10</td>\n",
       "      <td>EQKIKIYVTKRRFGKLMTIIEGFDTSVIDLKELAKKLKDICACGGT...</td>\n",
       "      <td>[(24, 102)]</td>\n",
       "      <td>79</td>\n",
       "      <td>[24, 102]</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>1vq8X00</td>\n",
       "      <td>1vq8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>440</td>\n",
       "      <td>10</td>\n",
       "      <td>2.20</td>\n",
       "      <td>ERVVTIPLRDARAEPNHKRADKAMILIREHLAKHFSVDEDAVRLDP...</td>\n",
       "      <td>[(7, 88)]</td>\n",
       "      <td>82</td>\n",
       "      <td>[7, 88]</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>1ze3D00</td>\n",
       "      <td>1ze3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>410</td>\n",
       "      <td>1.84</td>\n",
       "      <td>DLYFNPRFLLSRFENGQELPPGTYRVDIYLNNGYMATRDVTFNTGD...</td>\n",
       "      <td>[(1, 9), (19, 125)]</td>\n",
       "      <td>116</td>\n",
       "      <td>[1, 125]</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>3ejvA00</td>\n",
       "      <td>3ejv</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>450</td>\n",
       "      <td>50</td>\n",
       "      <td>1.40</td>\n",
       "      <td>TADETIILNVLGQYTRAHDRRDPDAAALFAPEATIEIVDAVGGASR...</td>\n",
       "      <td>[(2, 2), (4, 27), (29, 66), (69, 99), (101, 14...</td>\n",
       "      <td>152</td>\n",
       "      <td>[2, 160]</td>\n",
       "      <td>159</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6268 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cath_id pdb_id  class  architecture  topology  superfamily  \\\n",
       "0     2w3sB01   2w3s      3            90      1170           50   \n",
       "1     3be3A00   3be3      2            30        30          320   \n",
       "2     3zq4C03   3zq4      3            10        20          580   \n",
       "3     1peqA03   1peq      1            10      1650           20   \n",
       "4     1bdoA00   1bdo      2            40        50          100   \n",
       "...       ...    ...    ...           ...       ...          ...   \n",
       "6263  2yyiA02   2yyi      2            40       110           10   \n",
       "6264  4mo0A00   4mo0      3            30       780           10   \n",
       "6265  1vq8X00   1vq8      3            10       440           10   \n",
       "6266  1ze3D00   1ze3      3            10        20          410   \n",
       "6267  3ejvA00   3ejv      3            10       450           50   \n",
       "\n",
       "      resolution_in_angstroms  \\\n",
       "0                        2.60   \n",
       "1                        2.04   \n",
       "2                        3.00   \n",
       "3                        2.80   \n",
       "4                        1.80   \n",
       "...                       ...   \n",
       "6263                     1.66   \n",
       "6264                     2.10   \n",
       "6265                     2.20   \n",
       "6266                     1.84   \n",
       "6267                     1.40   \n",
       "\n",
       "                                               sequence  \\\n",
       "0     SVGKPLPHDSARAHVTGQARYLDDLPCPANTLHLAFGLSTEASAAI...   \n",
       "1     QDFRPGVYRHYKGDHYLALGLARADETDEVVVVYTRLYARAGLPST...   \n",
       "2     DIGNIVLRDRRILSEEGLVIVVVSIDMDDFKISAGPDLISRGFVIN...   \n",
       "3     DITFRLAKENAQMALFSPYDIQRRYGKPFGDIAISERYDELIADPH...   \n",
       "4     EISGHIVRSPMVGTFYRTPSPDAKAFIEVGQKVNVGDTLCIVEAMK...   \n",
       "...                                                 ...   \n",
       "6263  ATTHALTNPQVNRARPPSGQPDPYIPVGVVKQTEKGIVVRGARMTA...   \n",
       "6264  EQKIKIYVTKRRFGKLMTIIEGFDTSVIDLKELAKKLKDICACGGT...   \n",
       "6265  ERVVTIPLRDARAEPNHKRADKAMILIREHLAKHFSVDEDAVRLDP...   \n",
       "6266  DLYFNPRFLLSRFENGQELPPGTYRVDIYLNNGYMATRDVTFNTGD...   \n",
       "6267  TADETIILNVLGQYTRAHDRRDPDAAALFAPEATIEIVDAVGGASR...   \n",
       "\n",
       "                                            piece_edges  num_residues  \\\n",
       "0                                            [(2, 124)]           123   \n",
       "1                                   [(6, 49), (51, 81)]            75   \n",
       "2                              [(449, 492), (501, 555)]            99   \n",
       "3                                          [(294, 346)]            53   \n",
       "4                                           [(77, 156)]            80   \n",
       "...                                                 ...           ...   \n",
       "6263                           [(139, 196), (199, 266)]           126   \n",
       "6264                                        [(24, 102)]            79   \n",
       "6265                                          [(7, 88)]            82   \n",
       "6266                                [(1, 9), (19, 125)]           116   \n",
       "6267  [(2, 2), (4, 27), (29, 66), (69, 99), (101, 14...           152   \n",
       "\n",
       "     domain_edges  total_num_residues  num_gaps target  \n",
       "0        [2, 124]                 123         0    3.9  \n",
       "1         [6, 81]                  76         1    2.3  \n",
       "2      [449, 555]                 107         1    3.1  \n",
       "3      [294, 346]                  53         0    1.1  \n",
       "4       [77, 156]                  80         0    2.4  \n",
       "...           ...                 ...       ...    ...  \n",
       "6263   [139, 266]                 128         1    2.4  \n",
       "6264    [24, 102]                  79         0    3.3  \n",
       "6265      [7, 88]                  82         0    3.1  \n",
       "6266     [1, 125]                 125         1    3.1  \n",
       "6267     [2, 160]                 159         6    3.1  \n",
       "\n",
       "[6268 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6268 entries, 0 to 6267\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   cath_id                  6268 non-null   object \n",
      " 1   pdb_id                   6268 non-null   object \n",
      " 2   class                    6268 non-null   int64  \n",
      " 3   architecture             6268 non-null   int64  \n",
      " 4   topology                 6268 non-null   int64  \n",
      " 5   superfamily              6268 non-null   int64  \n",
      " 6   resolution_in_angstroms  6268 non-null   float64\n",
      " 7   sequence                 6268 non-null   object \n",
      " 8   piece_edges              6268 non-null   object \n",
      " 9   num_residues             6268 non-null   int64  \n",
      " 10  domain_edges             6268 non-null   object \n",
      " 11  total_num_residues       6268 non-null   int64  \n",
      " 12  num_gaps                 6268 non-null   int64  \n",
      " 13  target                   6268 non-null   object \n",
      "dtypes: float64(1), int64(7), object(6)\n",
      "memory usage: 734.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Open the training data sequences and structure\n",
    "proc_data = pd.read_csv(f\"{DATA_HOME}/data_processed.csv\", index_col=0)\n",
    "\n",
    "# Converting `piece_edges` and `domain_edges` into a proper format\n",
    "proc_data = proc_data.assign(\n",
    "    **{\n",
    "        \"piece_edges\": proc_data[\"piece_edges\"].apply(eval),\n",
    "        \"domain_edges\": proc_data[\"domain_edges\"].apply(eval),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Converting `target` to string format\n",
    "proc_data[\"target\"] = proc_data[\"target\"].astype(str)\n",
    "display(proc_data)\n",
    "\n",
    "# Get the schema of the data\n",
    "proc_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the counts of n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate the counts of n-grams in the available data. Please note the following considerations:\n",
    "\n",
    "- We will set `N=2`, i.e. we will calculate the counts of **bigrams**\n",
    "- We will take into consideration the gaps in data but abrupting the counts there\n",
    "- There could be a situation where a bigram is not present in the sequence piece (e.g. unigram) - we will drop those records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ngram_count(sequence, n):\n",
    "    \"\"\"\n",
    "    Calculates the count of n-grams in a given sequence.\n",
    "\n",
    "    Args:\n",
    "        sequence (str): The input sequence.\n",
    "        n (int): The length of the n-grams.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the n-grams as keys and their counts as values.\n",
    "    \"\"\"\n",
    "    ngram_count = {}\n",
    "    for i in range(len(sequence) - n + 1):\n",
    "        ngram = sequence[i : i + n]\n",
    "        if ngram in ngram_count:\n",
    "            ngram_count[ngram] += 1\n",
    "        else:\n",
    "            ngram_count[ngram] = 1\n",
    "    return ngram_count\n",
    "\n",
    "\n",
    "def create_sequence_set(seq, edges):\n",
    "    \"\"\"\n",
    "    This is a helper function that takes the sequence e.g. \"ABCDEFG\" and a list of edges [(0, 2), (2, 4)]\n",
    "    and returns a list of sequences [\"AB\", \"CD\", \"EF\"]\n",
    "\n",
    "    Parameters:\n",
    "        seq (str): The input sequence.\n",
    "        edges (list): A list of edges representing the start and end indices of subsequences in the input sequence.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of subsequences extracted from the input sequence based on the provided edges.\n",
    "    \"\"\"\n",
    "\n",
    "    return [seq[edge[0] : edge[1] + 1] for edge in edges]\n",
    "\n",
    "\n",
    "def process_row(row, n):\n",
    "    \"\"\"\n",
    "    This is a helper function that takes a row of the dataframe and based on `sequence` and `piece_edges`,\n",
    "    calculates the sequence set, and then calculates the ngram count for each sequence in the sequence set.\n",
    "    The n-gram count is then aggregated (summed) into a single dictionary and returned.\n",
    "\n",
    "    Args:\n",
    "        row (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    offset = row[\"piece_edges\"][0][0]\n",
    "    piece_edges_without_offset = [\n",
    "        (edge[0] - offset, edge[1] - offset) for edge in row[\"piece_edges\"]\n",
    "    ]\n",
    "\n",
    "    sequence = row[\"sequence\"]\n",
    "    sequence_set = create_sequence_set(sequence, piece_edges_without_offset)\n",
    "    ngram_count = {}\n",
    "    for seq in sequence_set:\n",
    "        ngram_count_seq = calculate_ngram_count(seq, n=n)\n",
    "        ngram_count = {\n",
    "            k: ngram_count.get(k, 0) + ngram_count_seq.get(k, 0)\n",
    "            for k in set(ngram_count) | set(ngram_count_seq)\n",
    "        }\n",
    "    return {f\"count_{k}\": v for k, v in ngram_count.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to calculate the counts! We will not forget to normalize the counts by the total number of bigrams in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_LP</th>\n",
       "      <th>count_ND</th>\n",
       "      <th>count_VI</th>\n",
       "      <th>count_SH</th>\n",
       "      <th>count_KA</th>\n",
       "      <th>count_LS</th>\n",
       "      <th>count_PI</th>\n",
       "      <th>count_YL</th>\n",
       "      <th>count_FV</th>\n",
       "      <th>count_RI</th>\n",
       "      <th>...</th>\n",
       "      <th>count_FC</th>\n",
       "      <th>count_RM</th>\n",
       "      <th>count_MC</th>\n",
       "      <th>count_WC</th>\n",
       "      <th>count_YH</th>\n",
       "      <th>count_NC</th>\n",
       "      <th>count_HC</th>\n",
       "      <th>count_NM</th>\n",
       "      <th>count_WM</th>\n",
       "      <th>count_CW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024590</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6263</th>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6268 rows Ã— 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      count_LP  count_ND  count_VI  count_SH  count_KA  count_LS  count_PI  \\\n",
       "0     0.024590  0.008197  0.008197  0.008197  0.008197  0.008197  0.008197   \n",
       "1     0.013889  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2     0.011236  0.000000  0.011236  0.000000  0.000000  0.011236  0.011236   \n",
       "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4     0.000000  0.000000  0.012658  0.000000  0.025316  0.000000  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6263  0.008197  0.000000  0.008197  0.000000  0.000000  0.008197  0.000000   \n",
       "6264  0.000000  0.000000  0.012821  0.000000  0.000000  0.000000  0.000000   \n",
       "6265  0.000000  0.000000  0.000000  0.000000  0.012346  0.000000  0.000000   \n",
       "6266  0.009524  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6267  0.000000  0.000000  0.014286  0.000000  0.000000  0.000000  0.014286   \n",
       "\n",
       "      count_YL  count_FV  count_RI  ...  count_FC  count_RM  count_MC  \\\n",
       "0     0.008197  0.008197  0.016393  ...       0.0  0.000000       0.0   \n",
       "1     0.013889  0.000000  0.013889  ...       0.0  0.000000       0.0   \n",
       "2     0.000000  0.011236  0.011236  ...       0.0  0.000000       0.0   \n",
       "3     0.000000  0.000000  0.000000  ...       0.0  0.000000       0.0   \n",
       "4     0.000000  0.000000  0.000000  ...       0.0  0.000000       0.0   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "6263  0.000000  0.008197  0.000000  ...       0.0  0.008197       0.0   \n",
       "6264  0.000000  0.000000  0.000000  ...       0.0  0.000000       0.0   \n",
       "6265  0.000000  0.000000  0.000000  ...       0.0  0.000000       0.0   \n",
       "6266  0.009524  0.000000  0.000000  ...       0.0  0.000000       0.0   \n",
       "6267  0.000000  0.007143  0.014286  ...       0.0  0.000000       0.0   \n",
       "\n",
       "      count_WC  count_YH  count_NC  count_HC  count_NM  count_WM  count_CW  \n",
       "0          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "1          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "3          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "4          0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "6263       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "6264       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "6265       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "6266       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "6267       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[6268 rows x 400 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2\n",
    "count_df = pd.DataFrame.from_records(\n",
    "    proc_data.apply(lambda row: process_row(row, N), axis=1)\n",
    ")\n",
    "\n",
    "# Filling missing values with 0\n",
    "count_df.fillna(0, inplace=True)\n",
    "\n",
    "# Normalize the count_df\n",
    "count_df = count_df.div(count_df.sum(axis=1), axis=0)\n",
    "\n",
    "count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's append this to the main dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cath_id</th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>class</th>\n",
       "      <th>architecture</th>\n",
       "      <th>topology</th>\n",
       "      <th>superfamily</th>\n",
       "      <th>resolution_in_angstroms</th>\n",
       "      <th>sequence</th>\n",
       "      <th>piece_edges</th>\n",
       "      <th>num_residues</th>\n",
       "      <th>...</th>\n",
       "      <th>count_FC</th>\n",
       "      <th>count_RM</th>\n",
       "      <th>count_MC</th>\n",
       "      <th>count_WC</th>\n",
       "      <th>count_YH</th>\n",
       "      <th>count_NC</th>\n",
       "      <th>count_HC</th>\n",
       "      <th>count_NM</th>\n",
       "      <th>count_WM</th>\n",
       "      <th>count_CW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2w3sB01</td>\n",
       "      <td>2w3s</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>1170</td>\n",
       "      <td>50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>SVGKPLPHDSARAHVTGQARYLDDLPCPANTLHLAFGLSTEASAAI...</td>\n",
       "      <td>[(2, 124)]</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3be3A00</td>\n",
       "      <td>3be3</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>320</td>\n",
       "      <td>2.04</td>\n",
       "      <td>QDFRPGVYRHYKGDHYLALGLARADETDEVVVVYTRLYARAGLPST...</td>\n",
       "      <td>[(6, 49), (51, 81)]</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3zq4C03</td>\n",
       "      <td>3zq4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>580</td>\n",
       "      <td>3.00</td>\n",
       "      <td>DIGNIVLRDRRILSEEGLVIVVVSIDMDDFKISAGPDLISRGFVIN...</td>\n",
       "      <td>[(449, 492), (501, 555)]</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1peqA03</td>\n",
       "      <td>1peq</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1650</td>\n",
       "      <td>20</td>\n",
       "      <td>2.80</td>\n",
       "      <td>DITFRLAKENAQMALFSPYDIQRRYGKPFGDIAISERYDELIADPH...</td>\n",
       "      <td>[(294, 346)]</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1bdoA00</td>\n",
       "      <td>1bdo</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>1.80</td>\n",
       "      <td>EISGHIVRSPMVGTFYRTPSPDAKAFIEVGQKVNVGDTLCIVEAMK...</td>\n",
       "      <td>[(77, 156)]</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6263</th>\n",
       "      <td>2yyiA02</td>\n",
       "      <td>2yyi</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>110</td>\n",
       "      <td>10</td>\n",
       "      <td>1.66</td>\n",
       "      <td>ATTHALTNPQVNRARPPSGQPDPYIPVGVVKQTEKGIVVRGARMTA...</td>\n",
       "      <td>[(139, 196), (199, 266)]</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>4mo0A00</td>\n",
       "      <td>4mo0</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>780</td>\n",
       "      <td>10</td>\n",
       "      <td>2.10</td>\n",
       "      <td>EQKIKIYVTKRRFGKLMTIIEGFDTSVIDLKELAKKLKDICACGGT...</td>\n",
       "      <td>[(24, 102)]</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>1vq8X00</td>\n",
       "      <td>1vq8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>440</td>\n",
       "      <td>10</td>\n",
       "      <td>2.20</td>\n",
       "      <td>ERVVTIPLRDARAEPNHKRADKAMILIREHLAKHFSVDEDAVRLDP...</td>\n",
       "      <td>[(7, 88)]</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>1ze3D00</td>\n",
       "      <td>1ze3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>410</td>\n",
       "      <td>1.84</td>\n",
       "      <td>DLYFNPRFLLSRFENGQELPPGTYRVDIYLNNGYMATRDVTFNTGD...</td>\n",
       "      <td>[(1, 9), (19, 125)]</td>\n",
       "      <td>116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>3ejvA00</td>\n",
       "      <td>3ejv</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>450</td>\n",
       "      <td>50</td>\n",
       "      <td>1.40</td>\n",
       "      <td>TADETIILNVLGQYTRAHDRRDPDAAALFAPEATIEIVDAVGGASR...</td>\n",
       "      <td>[(2, 2), (4, 27), (29, 66), (69, 99), (101, 14...</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6267 rows Ã— 414 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cath_id pdb_id  class  architecture  topology  superfamily  \\\n",
       "0     2w3sB01   2w3s      3            90      1170           50   \n",
       "1     3be3A00   3be3      2            30        30          320   \n",
       "2     3zq4C03   3zq4      3            10        20          580   \n",
       "3     1peqA03   1peq      1            10      1650           20   \n",
       "4     1bdoA00   1bdo      2            40        50          100   \n",
       "...       ...    ...    ...           ...       ...          ...   \n",
       "6263  2yyiA02   2yyi      2            40       110           10   \n",
       "6264  4mo0A00   4mo0      3            30       780           10   \n",
       "6265  1vq8X00   1vq8      3            10       440           10   \n",
       "6266  1ze3D00   1ze3      3            10        20          410   \n",
       "6267  3ejvA00   3ejv      3            10       450           50   \n",
       "\n",
       "      resolution_in_angstroms  \\\n",
       "0                        2.60   \n",
       "1                        2.04   \n",
       "2                        3.00   \n",
       "3                        2.80   \n",
       "4                        1.80   \n",
       "...                       ...   \n",
       "6263                     1.66   \n",
       "6264                     2.10   \n",
       "6265                     2.20   \n",
       "6266                     1.84   \n",
       "6267                     1.40   \n",
       "\n",
       "                                               sequence  \\\n",
       "0     SVGKPLPHDSARAHVTGQARYLDDLPCPANTLHLAFGLSTEASAAI...   \n",
       "1     QDFRPGVYRHYKGDHYLALGLARADETDEVVVVYTRLYARAGLPST...   \n",
       "2     DIGNIVLRDRRILSEEGLVIVVVSIDMDDFKISAGPDLISRGFVIN...   \n",
       "3     DITFRLAKENAQMALFSPYDIQRRYGKPFGDIAISERYDELIADPH...   \n",
       "4     EISGHIVRSPMVGTFYRTPSPDAKAFIEVGQKVNVGDTLCIVEAMK...   \n",
       "...                                                 ...   \n",
       "6263  ATTHALTNPQVNRARPPSGQPDPYIPVGVVKQTEKGIVVRGARMTA...   \n",
       "6264  EQKIKIYVTKRRFGKLMTIIEGFDTSVIDLKELAKKLKDICACGGT...   \n",
       "6265  ERVVTIPLRDARAEPNHKRADKAMILIREHLAKHFSVDEDAVRLDP...   \n",
       "6266  DLYFNPRFLLSRFENGQELPPGTYRVDIYLNNGYMATRDVTFNTGD...   \n",
       "6267  TADETIILNVLGQYTRAHDRRDPDAAALFAPEATIEIVDAVGGASR...   \n",
       "\n",
       "                                            piece_edges  num_residues  ...  \\\n",
       "0                                            [(2, 124)]           123  ...   \n",
       "1                                   [(6, 49), (51, 81)]            75  ...   \n",
       "2                              [(449, 492), (501, 555)]            99  ...   \n",
       "3                                          [(294, 346)]            53  ...   \n",
       "4                                           [(77, 156)]            80  ...   \n",
       "...                                                 ...           ...  ...   \n",
       "6263                           [(139, 196), (199, 266)]           126  ...   \n",
       "6264                                        [(24, 102)]            79  ...   \n",
       "6265                                          [(7, 88)]            82  ...   \n",
       "6266                                [(1, 9), (19, 125)]           116  ...   \n",
       "6267  [(2, 2), (4, 27), (29, 66), (69, 99), (101, 14...           152  ...   \n",
       "\n",
       "     count_FC  count_RM  count_MC count_WC  count_YH  count_NC  count_HC  \\\n",
       "0         0.0  0.000000       0.0      0.0       0.0       0.0       0.0   \n",
       "1         0.0  0.000000       0.0      0.0       0.0       0.0       0.0   \n",
       "2         0.0  0.000000       0.0      0.0       0.0       0.0       0.0   \n",
       "3         0.0  0.000000       0.0      0.0       0.0       0.0       0.0   \n",
       "4         0.0  0.000000       0.0      0.0       0.0       0.0       0.0   \n",
       "...       ...       ...       ...      ...       ...       ...       ...   \n",
       "6263      0.0  0.008197       0.0      0.0       0.0       0.0       0.0   \n",
       "6264      0.0  0.000000       0.0      0.0       0.0       0.0       0.0   \n",
       "6265      0.0  0.000000       0.0      0.0       0.0       0.0       0.0   \n",
       "6266      0.0  0.000000       0.0      0.0       0.0       0.0       0.0   \n",
       "6267      0.0  0.000000       0.0      0.0       0.0       0.0       0.0   \n",
       "\n",
       "      count_NM  count_WM  count_CW  \n",
       "0          0.0       0.0       0.0  \n",
       "1          0.0       0.0       0.0  \n",
       "2          0.0       0.0       0.0  \n",
       "3          0.0       0.0       0.0  \n",
       "4          0.0       0.0       0.0  \n",
       "...        ...       ...       ...  \n",
       "6263       0.0       0.0       0.0  \n",
       "6264       0.0       0.0       0.0  \n",
       "6265       0.0       0.0       0.0  \n",
       "6266       0.0       0.0       0.0  \n",
       "6267       0.0       0.0       0.0  \n",
       "\n",
       "[6267 rows x 414 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating the processed data and the count dataframe, dropping unigrams\n",
    "master_df = pd.concat([proc_data, count_df], axis=1).dropna(axis=\"rows\")\n",
    "\n",
    "master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to split the data into train and test sets. We will use 80% of the data for training and 20% for testing.\n",
    "\n",
    "Based on the comment:\n",
    "> One common challenge when working with protein data is that some sequences and\n",
    "structures may originate from evolutionarily related organisms (also called homologous proteins). This can cause issues because related proteins can be really similar to each other, so when a model is evaluated on a protein that is related to one that it has been trained on, it will likely be more accurate because of data leakage. Thus, we will want to account when splitting data, to make sure we are fairly assessing the model performance and generalizability.\n",
    "> - For the dataset that we are working with, proteins that are in the **same Homologous superfamily (H) level** in the CATH hierarchy are **related**, so you will want to split the dataset to account for this.\n",
    "\n",
    "We will have to stratify the split based on the `superfamily` column. Let us double check the distribution of the `superfamily` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "superfamily\n",
       "10       1798\n",
       "20        401\n",
       "30        291\n",
       "40        196\n",
       "140       157\n",
       "         ... \n",
       "12600       1\n",
       "12710       1\n",
       "4820        1\n",
       "11810       1\n",
       "2490        1\n",
       "Name: count, Length: 604, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df[\"superfamily\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that some classes are underrepresented, i.e. there is only one sample per `superfamily` class. We will put them all in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cath_id</th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>class</th>\n",
       "      <th>architecture</th>\n",
       "      <th>topology</th>\n",
       "      <th>superfamily</th>\n",
       "      <th>resolution_in_angstroms</th>\n",
       "      <th>sequence</th>\n",
       "      <th>piece_edges</th>\n",
       "      <th>num_residues</th>\n",
       "      <th>...</th>\n",
       "      <th>count_FC</th>\n",
       "      <th>count_RM</th>\n",
       "      <th>count_MC</th>\n",
       "      <th>count_WC</th>\n",
       "      <th>count_YH</th>\n",
       "      <th>count_NC</th>\n",
       "      <th>count_HC</th>\n",
       "      <th>count_NM</th>\n",
       "      <th>count_WM</th>\n",
       "      <th>count_CW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>4rbnA01</td>\n",
       "      <td>4rbn</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>450</td>\n",
       "      <td>330</td>\n",
       "      <td>3.05</td>\n",
       "      <td>IDTLATCTQQNRDAVYTLLRRYFTANRTLLLQSDLREGLLQTEQDC...</td>\n",
       "      <td>[(4, 132)]</td>\n",
       "      <td>129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>1v58A01</td>\n",
       "      <td>1v58</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>450</td>\n",
       "      <td>70</td>\n",
       "      <td>1.70</td>\n",
       "      <td>ELPAPVKAIEKQGITIIKTFDAPGGMKGYLGKYQDMGVTIYLTPDG...</td>\n",
       "      <td>[(2, 72)]</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>4e6uA02</td>\n",
       "      <td>4e6u</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1180</td>\n",
       "      <td>10</td>\n",
       "      <td>1.41</td>\n",
       "      <td>INIEGMRRKGWSKNTIQGLREAYKLIFKSGLTSVQAIDQIKSEILP...</td>\n",
       "      <td>[(196, 262)]</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>3lgdA00</td>\n",
       "      <td>3lgd</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>2.00</td>\n",
       "      <td>SIDETRAHLLLKEKMMRLGGRLVLNTKEELANERLMTLKIAEMKEA...</td>\n",
       "      <td>[(3, 484)]</td>\n",
       "      <td>482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>2v3mA00</td>\n",
       "      <td>2v3m</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>230</td>\n",
       "      <td>2.74</td>\n",
       "      <td>VPELPEDYEISEKTIITPIGVLKSAFENNIIIHATRVLKEGSIFCL...</td>\n",
       "      <td>[(122, 156), (162, 179), (181, 220)]</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>3uh8A00</td>\n",
       "      <td>3uh8</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>3350</td>\n",
       "      <td>2.30</td>\n",
       "      <td>MTEHFITLSTTEPNNNIGIVKLRHADVNSQAIVAQIVENGQPKNFE...</td>\n",
       "      <td>[(1, 58), (64, 123)]</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165</th>\n",
       "      <td>2vdwB02</td>\n",
       "      <td>2vdw</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>11680</td>\n",
       "      <td>2.70</td>\n",
       "      <td>PESDLDKVYEILKINSVKYYGRSTKADAVVADLSARNKLFKRERDA...</td>\n",
       "      <td>[(71, 119), (124, 201)]</td>\n",
       "      <td>127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>3lzdA03</td>\n",
       "      <td>3lzd</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>11860</td>\n",
       "      <td>2.10</td>\n",
       "      <td>PERFIRKRWAQIAKAMDAKKFGVIVSIKKGQLRLAEAKRIVKLLKK...</td>\n",
       "      <td>[(211, 312)]</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>4dmzA02</td>\n",
       "      <td>4dmz</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>2880</td>\n",
       "      <td>2.10</td>\n",
       "      <td>IDAQRFSQYLKRSLLDARDHGLPACLYAFELTDARYGEEVQRLLEG...</td>\n",
       "      <td>[(319, 455)]</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>4bqnA02</td>\n",
       "      <td>4bqn</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2490</td>\n",
       "      <td>1.38</td>\n",
       "      <td>PTVNSPYGLPPHPEGYVDALIAGAVVMDVDKETYLRHLEEIGASLR...</td>\n",
       "      <td>[(105, 153), (235, 312)]</td>\n",
       "      <td>127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5058 rows Ã— 414 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cath_id pdb_id  class  architecture  topology  superfamily  \\\n",
       "131   4rbnA01   4rbn      3            10       450          330   \n",
       "1646  1v58A01   1v58      3            10       450           70   \n",
       "5389  4e6uA02   4e6u      1            20      1180           10   \n",
       "2184  3lgdA00   3lgd      3            20        20          140   \n",
       "2724  2v3mA00   2v3m      2            40        10          230   \n",
       "...       ...    ...    ...           ...       ...          ...   \n",
       "6143  3uh8A00   3uh8      2            60        40         3350   \n",
       "6165  2vdwB02   2vdw      3            40        50        11680   \n",
       "6191  3lzdA03   3lzd      3            40        50        11860   \n",
       "6249  4dmzA02   4dmz      3            30        70         2880   \n",
       "6252  4bqnA02   4bqn      1            10        10         2490   \n",
       "\n",
       "      resolution_in_angstroms  \\\n",
       "131                      3.05   \n",
       "1646                     1.70   \n",
       "5389                     1.41   \n",
       "2184                     2.00   \n",
       "2724                     2.74   \n",
       "...                       ...   \n",
       "6143                     2.30   \n",
       "6165                     2.70   \n",
       "6191                     2.10   \n",
       "6249                     2.10   \n",
       "6252                     1.38   \n",
       "\n",
       "                                               sequence  \\\n",
       "131   IDTLATCTQQNRDAVYTLLRRYFTANRTLLLQSDLREGLLQTEQDC...   \n",
       "1646  ELPAPVKAIEKQGITIIKTFDAPGGMKGYLGKYQDMGVTIYLTPDG...   \n",
       "5389  INIEGMRRKGWSKNTIQGLREAYKLIFKSGLTSVQAIDQIKSEILP...   \n",
       "2184  SIDETRAHLLLKEKMMRLGGRLVLNTKEELANERLMTLKIAEMKEA...   \n",
       "2724  VPELPEDYEISEKTIITPIGVLKSAFENNIIIHATRVLKEGSIFCL...   \n",
       "...                                                 ...   \n",
       "6143  MTEHFITLSTTEPNNNIGIVKLRHADVNSQAIVAQIVENGQPKNFE...   \n",
       "6165  PESDLDKVYEILKINSVKYYGRSTKADAVVADLSARNKLFKRERDA...   \n",
       "6191  PERFIRKRWAQIAKAMDAKKFGVIVSIKKGQLRLAEAKRIVKLLKK...   \n",
       "6249  IDAQRFSQYLKRSLLDARDHGLPACLYAFELTDARYGEEVQRLLEG...   \n",
       "6252  PTVNSPYGLPPHPEGYVDALIAGAVVMDVDKETYLRHLEEIGASLR...   \n",
       "\n",
       "                               piece_edges  num_residues  ...  count_FC  \\\n",
       "131                             [(4, 132)]           129  ...  0.000000   \n",
       "1646                             [(2, 72)]            71  ...  0.000000   \n",
       "5389                          [(196, 262)]            67  ...  0.000000   \n",
       "2184                            [(3, 484)]           482  ...  0.000000   \n",
       "2724  [(122, 156), (162, 179), (181, 220)]            93  ...  0.011905   \n",
       "...                                    ...           ...  ...       ...   \n",
       "6143                  [(1, 58), (64, 123)]           118  ...  0.009009   \n",
       "6165               [(71, 119), (124, 201)]           127  ...  0.000000   \n",
       "6191                          [(211, 312)]           102  ...  0.000000   \n",
       "6249                          [(319, 455)]           137  ...  0.000000   \n",
       "6252              [(105, 153), (235, 312)]           127  ...  0.000000   \n",
       "\n",
       "      count_RM  count_MC count_WC  count_YH  count_NC  count_HC  count_NM  \\\n",
       "131   0.000000       0.0      0.0  0.000000       0.0  0.000000       0.0   \n",
       "1646  0.000000       0.0      0.0  0.000000       0.0  0.000000       0.0   \n",
       "5389  0.000000       0.0      0.0  0.000000       0.0  0.000000       0.0   \n",
       "2184  0.004158       0.0      0.0  0.000000       0.0  0.002079       0.0   \n",
       "2724  0.000000       0.0      0.0  0.000000       0.0  0.000000       0.0   \n",
       "...        ...       ...      ...       ...       ...       ...       ...   \n",
       "6143  0.000000       0.0      0.0  0.000000       0.0  0.000000       0.0   \n",
       "6165  0.000000       0.0      0.0  0.000000       0.0  0.000000       0.0   \n",
       "6191  0.000000       0.0      0.0  0.009901       0.0  0.000000       0.0   \n",
       "6249  0.000000       0.0      0.0  0.000000       0.0  0.000000       0.0   \n",
       "6252  0.000000       0.0      0.0  0.000000       0.0  0.000000       0.0   \n",
       "\n",
       "      count_WM  count_CW  \n",
       "131        0.0       0.0  \n",
       "1646       0.0       0.0  \n",
       "5389       0.0       0.0  \n",
       "2184       0.0       0.0  \n",
       "2724       0.0       0.0  \n",
       "...        ...       ...  \n",
       "6143       0.0       0.0  \n",
       "6165       0.0       0.0  \n",
       "6191       0.0       0.0  \n",
       "6249       0.0       0.0  \n",
       "6252       0.0       0.0  \n",
       "\n",
       "[5058 rows x 414 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cath_id</th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>class</th>\n",
       "      <th>architecture</th>\n",
       "      <th>topology</th>\n",
       "      <th>superfamily</th>\n",
       "      <th>resolution_in_angstroms</th>\n",
       "      <th>sequence</th>\n",
       "      <th>piece_edges</th>\n",
       "      <th>num_residues</th>\n",
       "      <th>...</th>\n",
       "      <th>count_FC</th>\n",
       "      <th>count_RM</th>\n",
       "      <th>count_MC</th>\n",
       "      <th>count_WC</th>\n",
       "      <th>count_YH</th>\n",
       "      <th>count_NC</th>\n",
       "      <th>count_HC</th>\n",
       "      <th>count_NM</th>\n",
       "      <th>count_WM</th>\n",
       "      <th>count_CW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>5bmnA03</td>\n",
       "      <td>5bmn</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>1.27</td>\n",
       "      <td>DHTGRFIEGYYLVGLLAQAILAKQPGGKVVHDPRLTWNTVEQVEEA...</td>\n",
       "      <td>[(269, 387)]</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>1bcpB01</td>\n",
       "      <td>1bcp</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>2.70</td>\n",
       "      <td>GIVIPPQEQITQHGSPYGRCANKTRALTVAELRGSGDLQEYLRHVT...</td>\n",
       "      <td>[(4, 89)]</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>1dmgA00</td>\n",
       "      <td>1dmg</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>1370</td>\n",
       "      <td>10</td>\n",
       "      <td>1.70</td>\n",
       "      <td>AQVDLLNVKGEKVGTLEISDFVFNIDPNYDVMWRYVDMQLSDWSKK...</td>\n",
       "      <td>[(2, 42), (96, 226)]</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3815</th>\n",
       "      <td>1ltzA00</td>\n",
       "      <td>1ltz</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>10</td>\n",
       "      <td>1.40</td>\n",
       "      <td>FVVPDITTRKNVGLSHDANDFTLPQPLDRYSAEDHATWATLYQRQC...</td>\n",
       "      <td>[(7, 253), (257, 283)]</td>\n",
       "      <td>274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>2evrA01</td>\n",
       "      <td>2evr</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>1.60</td>\n",
       "      <td>KLGEYQCLADLNLFDSPECTRLATQSASGRHLWVTSNHQNLAVEVY...</td>\n",
       "      <td>[(13, 86)]</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>3bb7A01</td>\n",
       "      <td>3bb7</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>ANQLRELKQTHTYTVFGYTDGGFAVISADDLAPELLGVSESNFVET...</td>\n",
       "      <td>[(39, 126), (261, 294), (302, 353)]</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>4dqaA01</td>\n",
       "      <td>4dqa</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>1740</td>\n",
       "      <td>1.50</td>\n",
       "      <td>PKVYFESKEYNFSVEDEDVTFDLVSRLSSATSSQVDVSYSVAEPSV...</td>\n",
       "      <td>[(32, 48), (50, 51), (53, 92), (94, 137), (139...</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>3duzA02</td>\n",
       "      <td>3duz</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>710</td>\n",
       "      <td>2.95</td>\n",
       "      <td>TFTTRQIKAACLLIKDDKNNPESVTREHCLIDNDIYDLSKNTWNCK...</td>\n",
       "      <td>[(218, 271)]</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>2w9yA00</td>\n",
       "      <td>2w9y</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>120</td>\n",
       "      <td>1100</td>\n",
       "      <td>1.80</td>\n",
       "      <td>GAMSVASLPEVKNFFPTEQLEFSSSITADEKPVLHEVFQKHSCGEM...</td>\n",
       "      <td>[(-1, 8), (10, 41), (46, 138)]</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>5ylyA01</td>\n",
       "      <td>5yly</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1.76</td>\n",
       "      <td>APFLNPKKQKAAELKEKIKISHDVTLFRFGLEHDEQLLGLPTGKHM...</td>\n",
       "      <td>[(596, 648), (655, 713)]</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1209 rows Ã— 414 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cath_id pdb_id  class  architecture  topology  superfamily  \\\n",
       "4576  5bmnA03   5bmn      3            40       120           10   \n",
       "3954  1bcpB01   1bcp      3            10        40           10   \n",
       "1720  1dmgA00   1dmg      3            40      1370           10   \n",
       "3815  1ltzA00   1ltz      1            10       800           10   \n",
       "3823  2evrA01   2evr      2            30        30           40   \n",
       "...       ...    ...    ...           ...       ...          ...   \n",
       "1061  3bb7A01   3bb7      3            90        70           50   \n",
       "4732  4dqaA01   4dqa      2            60        40         1740   \n",
       "3772  3duzA02   3duz      2            40        50          710   \n",
       "3163  2w9yA00   2w9y      1            20       120         1100   \n",
       "2870  5ylyA01   5yly      2            40        30           10   \n",
       "\n",
       "      resolution_in_angstroms  \\\n",
       "4576                     1.27   \n",
       "3954                     2.70   \n",
       "1720                     1.70   \n",
       "3815                     1.40   \n",
       "3823                     1.60   \n",
       "...                       ...   \n",
       "1061                     1.50   \n",
       "4732                     1.50   \n",
       "3772                     2.95   \n",
       "3163                     1.80   \n",
       "2870                     1.76   \n",
       "\n",
       "                                               sequence  \\\n",
       "4576  DHTGRFIEGYYLVGLLAQAILAKQPGGKVVHDPRLTWNTVEQVEEA...   \n",
       "3954  GIVIPPQEQITQHGSPYGRCANKTRALTVAELRGSGDLQEYLRHVT...   \n",
       "1720  AQVDLLNVKGEKVGTLEISDFVFNIDPNYDVMWRYVDMQLSDWSKK...   \n",
       "3815  FVVPDITTRKNVGLSHDANDFTLPQPLDRYSAEDHATWATLYQRQC...   \n",
       "3823  KLGEYQCLADLNLFDSPECTRLATQSASGRHLWVTSNHQNLAVEVY...   \n",
       "...                                                 ...   \n",
       "1061  ANQLRELKQTHTYTVFGYTDGGFAVISADDLAPELLGVSESNFVET...   \n",
       "4732  PKVYFESKEYNFSVEDEDVTFDLVSRLSSATSSQVDVSYSVAEPSV...   \n",
       "3772  TFTTRQIKAACLLIKDDKNNPESVTREHCLIDNDIYDLSKNTWNCK...   \n",
       "3163  GAMSVASLPEVKNFFPTEQLEFSSSITADEKPVLHEVFQKHSCGEM...   \n",
       "2870  APFLNPKKQKAAELKEKIKISHDVTLFRFGLEHDEQLLGLPTGKHM...   \n",
       "\n",
       "                                            piece_edges  num_residues  ...  \\\n",
       "4576                                       [(269, 387)]           119  ...   \n",
       "3954                                          [(4, 89)]            86  ...   \n",
       "1720                               [(2, 42), (96, 226)]           172  ...   \n",
       "3815                             [(7, 253), (257, 283)]           274  ...   \n",
       "3823                                         [(13, 86)]            74  ...   \n",
       "...                                                 ...           ...  ...   \n",
       "1061                [(39, 126), (261, 294), (302, 353)]           174  ...   \n",
       "4732  [(32, 48), (50, 51), (53, 92), (94, 137), (139...           128  ...   \n",
       "3772                                       [(218, 271)]            54  ...   \n",
       "3163                     [(-1, 8), (10, 41), (46, 138)]           135  ...   \n",
       "2870                           [(596, 648), (655, 713)]           112  ...   \n",
       "\n",
       "      count_FC  count_RM  count_MC count_WC  count_YH  count_NC  count_HC  \\\n",
       "4576  0.000000  0.008475       0.0      0.0       0.0  0.000000  0.000000   \n",
       "3954  0.011765  0.000000       0.0      0.0       0.0  0.000000  0.000000   \n",
       "1720  0.000000  0.000000       0.0      0.0       0.0  0.000000  0.000000   \n",
       "3815  0.000000  0.000000       0.0      0.0       0.0  0.000000  0.000000   \n",
       "3823  0.000000  0.000000       0.0      0.0       0.0  0.000000  0.000000   \n",
       "...        ...       ...       ...      ...       ...       ...       ...   \n",
       "1061  0.000000  0.000000       0.0      0.0       0.0  0.000000  0.000000   \n",
       "4732  0.000000  0.000000       0.0      0.0       0.0  0.000000  0.000000   \n",
       "3772  0.000000  0.000000       0.0      0.0       0.0  0.018868  0.018868   \n",
       "3163  0.000000  0.000000       0.0      0.0       0.0  0.000000  0.000000   \n",
       "2870  0.000000  0.000000       0.0      0.0       0.0  0.000000  0.000000   \n",
       "\n",
       "      count_NM  count_WM  count_CW  \n",
       "4576       0.0       0.0       0.0  \n",
       "3954       0.0       0.0       0.0  \n",
       "1720       0.0       0.0       0.0  \n",
       "3815       0.0       0.0       0.0  \n",
       "3823       0.0       0.0       0.0  \n",
       "...        ...       ...       ...  \n",
       "1061       0.0       0.0       0.0  \n",
       "4732       0.0       0.0       0.0  \n",
       "3772       0.0       0.0       0.0  \n",
       "3163       0.0       0.0       0.0  \n",
       "2870       0.0       0.0       0.0  \n",
       "\n",
       "[1209 rows x 414 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SPLIT = 0.2  # 20% of the data will be used for testing\n",
    "\n",
    "# Identify classes in 'superfamily' with only one sample\n",
    "single_sample_classes = (\n",
    "    master_df[\"superfamily\"].value_counts().loc[lambda x: x == 1].index\n",
    ")\n",
    "\n",
    "# Separate these into a different DataFrame\n",
    "single_sample_df = master_df[master_df[\"superfamily\"].isin(single_sample_classes)]\n",
    "\n",
    "# Remove these samples from the original DataFrame\n",
    "trunc_master_df = master_df[~master_df[\"superfamily\"].isin(single_sample_classes)]\n",
    "\n",
    "# Perform stratified train-test split on the remaining data\n",
    "train_master, test_master = train_test_split(\n",
    "    trunc_master_df,\n",
    "    test_size=SPLIT,\n",
    "    random_state=SEED,\n",
    "    stratify=trunc_master_df[\"superfamily\"],\n",
    ")\n",
    "\n",
    "# Add the single sample classes to the test set\n",
    "train_master = pd.concat([train_master, single_sample_df])\n",
    "\n",
    "print(\"Train set:\")\n",
    "display(train_master)\n",
    "\n",
    "print(\"Test set:\")\n",
    "display(test_master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `X` and `y` arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (5058, 400)\n",
      "Test set shape: (1209, 400)\n"
     ]
    }
   ],
   "source": [
    "# Create X and y arrays from train_master\n",
    "X_train = train_master.filter(regex=\"^count_\")\n",
    "y_train = train_master[\"target\"]\n",
    "\n",
    "# Create X and y arrays from test_master\n",
    "X_test = test_master.filter(regex=\"^count_\")\n",
    "y_test = test_master[\"target\"]\n",
    "\n",
    "# Train set\n",
    "print(f\"Train set shape: {X_train.shape}\")\n",
    "\n",
    "# Test set\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training benchmarking random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a benchmark we will start with a standard random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Score: 0.9978252273625939\n",
      "Test Accuracy Score: 0.20926385442514475\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.1       0.16      0.21      0.18       119\n",
      "         1.2       0.22      0.32      0.26       114\n",
      "         2.3       0.18      0.19      0.18       129\n",
      "         2.4       0.22      0.15      0.18       142\n",
      "         2.6       0.24      0.37      0.29       109\n",
      "         3.1       0.10      0.06      0.08       131\n",
      "         3.2       0.44      0.60      0.50       121\n",
      "         3.3       0.08      0.05      0.06       127\n",
      "         3.4       0.07      0.10      0.09        81\n",
      "         3.9       0.17      0.08      0.11       136\n",
      "\n",
      "    accuracy                           0.21      1209\n",
      "   macro avg       0.19      0.21      0.19      1209\n",
      "weighted avg       0.19      0.21      0.19      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "n_components = 100\n",
    "\n",
    "best_model = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"pca\",\n",
    "            PCA(n_components=n_components),\n",
    "        ),  # Specify the number of components for PCA\n",
    "        (\"rf\", RandomForestClassifier(random_state=SEED, n_estimators=20)),  # Random Forest classifier\n",
    "    ]\n",
    ")\n",
    "# best_model = RandomForestClassifier(n_estimators=20, random_state=SEED)\n",
    "\n",
    "# Train the best model on the training set\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable on the train and test sets\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the best parameters and the accuracy scores\n",
    "print(\"Train Accuracy Score:\", train_accuracy)\n",
    "print(\"Test Accuracy Score:\", test_accuracy)\n",
    "\n",
    "# Print the classification report for the test set\n",
    "print(\"Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Train Accuracy Score: 0.9971032484998965\n",
      "Test Accuracy Score: 0.29707112970711297\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.1       0.27      0.39      0.32       127\n",
      "         1.2       0.30      0.46      0.36       122\n",
      "         2.3       0.23      0.37      0.28       129\n",
      "         2.4       0.24      0.18      0.20       142\n",
      "         2.6       0.45      0.43      0.44       171\n",
      "         3.1       0.11      0.06      0.08       131\n",
      "         3.2       0.45      0.94      0.60       121\n",
      "         3.3       0.22      0.11      0.14       147\n",
      "         3.4       0.38      0.07      0.12       208\n",
      "         3.9       0.16      0.16      0.16       136\n",
      "\n",
      "    accuracy                           0.30      1434\n",
      "   macro avg       0.28      0.32      0.27      1434\n",
      "weighted avg       0.29      0.30      0.26      1434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 50, 100, 200, 300],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Create the random forest classifier\n",
    "rf = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Train the best model on the training set\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable on the train and test sets\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the best parameters and the accuracy scores\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Train Accuracy Score:\", train_accuracy)\n",
    "print(\"Test Accuracy Score:\", test_accuracy)\n",
    "\n",
    "# Print the classification report for the test set\n",
    "print(\"Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model seriously overfits. Let's decrease the dimensionality with PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training PCA + random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - Cumulative explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a PCA object\n",
    "pca = PCA()\n",
    "\n",
    "# Fit the PCA on the training data\n",
    "pca.fit(X_train)\n",
    "\n",
    "# Calculate the cumulative explained variance ratio\n",
    "cumulative_explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot the cumulative explained variance ratio\n",
    "plt.plot(\n",
    "    range(1, len(cumulative_explained_variance_ratio) + 1),\n",
    "    cumulative_explained_variance_ratio,\n",
    "    marker=\"o\",\n",
    ")\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance Ratio\")\n",
    "plt.title(\"Cumulative Explained Variance Ratio by Number of Principal Components\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So let's keep the first 250 principal components because we see that they explain 90% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'pca__n_components': 100, 'rf__max_depth': None, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 10, 'rf__n_estimators': 300}\n",
      "Train Accuracy Score: 0.9983447134285123\n",
      "Test Accuracy Score: 0.25453277545327757\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.1       0.21      0.22      0.21       127\n",
      "         1.2       0.29      0.52      0.37       122\n",
      "         2.3       0.21      0.24      0.22       129\n",
      "         2.4       0.17      0.15      0.16       142\n",
      "         2.6       0.37      0.43      0.39       171\n",
      "         3.1       0.11      0.08      0.09       131\n",
      "         3.2       0.40      0.88      0.54       121\n",
      "         3.3       0.10      0.05      0.07       147\n",
      "         3.4       0.25      0.06      0.09       208\n",
      "         3.9       0.10      0.09      0.09       136\n",
      "\n",
      "    accuracy                           0.25      1434\n",
      "   macro avg       0.22      0.27      0.23      1434\n",
      "weighted avg       0.22      0.25      0.22      1434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the default number of components\n",
    "n_components = 250\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"pca\",\n",
    "            PCA(n_components=n_components),\n",
    "        ),  # Specify the number of components for PCA\n",
    "        (\"rf\", RandomForestClassifier(random_state=SEED)),  # Random Forest classifier\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    \"pca__n_components\": [100, 200, 250],  # Number of components for PCA\n",
    "    \"rf__n_estimators\": [10, 50, 100, 200, 300],\n",
    "    \"rf__max_depth\": [None, 5, 10],\n",
    "    \"rf__min_samples_split\": [2, 5, 10],\n",
    "    \"rf__min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Train the best model on the training set\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable on the train and test sets\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the best parameters and the accuracy scores\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Train Accuracy Score:\", train_accuracy)\n",
    "print(\"Test Accuracy Score:\", test_accuracy)\n",
    "\n",
    "# Print the classification report for the test set\n",
    "print(\"Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'n_estimators': 50}\n",
      "Train Accuracy Score: 0.9615145872129113\n",
      "Test Accuracy Score: 0.2594142259414226\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.1       0.23      0.35      0.28       127\n",
      "         1.2       0.29      0.42      0.34       122\n",
      "         2.3       0.19      0.29      0.23       129\n",
      "         2.4       0.16      0.13      0.14       142\n",
      "         2.6       0.33      0.31      0.32       171\n",
      "         3.1       0.14      0.08      0.10       131\n",
      "         3.2       0.43      0.89      0.58       121\n",
      "         3.3       0.14      0.10      0.11       147\n",
      "         3.4       0.33      0.08      0.12       208\n",
      "         3.9       0.16      0.14      0.15       136\n",
      "\n",
      "    accuracy                           0.26      1434\n",
      "   macro avg       0.24      0.28      0.24      1434\n",
      "weighted avg       0.24      0.26      0.23      1434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 25, 50],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "}\n",
    "\n",
    "# Create the random forest classifier\n",
    "rf = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Train the best model on the training set\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable on the train and test sets\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the best parameters and the accuracy scores\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Train Accuracy Score:\", train_accuracy)\n",
    "print(\"Test Accuracy Score:\", test_accuracy)\n",
    "\n",
    "# Print the classification report for the test set\n",
    "print(\"Classification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
